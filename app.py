import os, io, tempfile, json, time, logging
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse
from pydub import AudioSegment
from faster_whisper import WhisperModel
import whisperx
import torch

# ×”×’×“×¨×ª ×œ×•×’×™×
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ×™×¦×™×¨×ª ××¤×œ×™×§×¦×™×™×ª FastAPI
app = FastAPI(title="×ª××œ×•×œ ×•×–×™×”×•×™ ×“×•×‘×¨×™× - WhisperX", version="2.0.0")

# ×”×’×“×¨×ª CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ××©×ª× ×™× ×’×œ×•×‘×œ×™×™×
asr = None
dia = None

def load_models():
    """×˜×¢×™× ×ª ×”××•×“×œ×™× ×¤×¢× ××—×ª"""
    global asr, dia
    if asr is None or dia is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info(f"ğŸš€ ×˜×•×¢×Ÿ ××•×“×œ×™× ×¢×œ: {device}")

        # ×ª××œ×•×œ ×¢× Whisper
        model_size = os.getenv("WHISPER_MODEL", "small")
        logger.info(f"ğŸ—£ï¸ ×˜×•×¢×Ÿ Whisper {model_size}")
        asr = WhisperModel(model_size, device=device, compute_type="float16" if device == "cuda" else "int8")

        # ×–×™×”×•×™ ×“×•×‘×¨×™× ×¢× WhisperX
        logger.info("ğŸ™ï¸ ×˜×•×¢×Ÿ ××•×“×œ ×–×™×”×•×™ ×“×•×‘×¨×™× ×©×œ WhisperX...")
        dia = whisperx.DiarizationPipeline(use_auth_token=None, device=device)

        logger.info("âœ… ×›×œ ×”××•×“×œ×™× × ×˜×¢× ×• ×‘×”×¦×œ×—×”!")

@app.on_event("startup")
async def startup_event():
    load_models()

def to_wav_16k_mono(upload: UploadFile) -> str:
    """×”××¨×ª ×§×•×‘×¥ ×œ××•×“×™×• WAV 16kHz ××•× ×•"""
    data = upload.file.read()
    if not data:
        raise HTTPException(400, "×§×•×‘×¥ ×¨×™×§")
    audio = AudioSegment.from_file(io.BytesIO(data))
    audio = audio.set_frame_rate(16000).set_channels(1)
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    audio.export(tmp.name, format="wav")
    return tmp.name

@app.get("/", response_class=HTMLResponse)
async def home():
    return "<h1>WhisperX Server ×¤×¢×™×œ âœ…</h1>"

@app.post("/transcribe")
async def transcribe(file: UploadFile = File(...), language: str = "he"):
    """×ª××œ×•×œ ×§×•×‘×¥ ×¢× ×–×™×”×•×™ ×“×•×‘×¨×™×"""
    wav_path = None
    try:
        start_time = time.time()
        logger.info(f"ğŸ§ ×”×ª×—×œ×ª ×ª××œ×•×œ: {file.filename}")
        load_models()

        # ×”××¨×ª ×§×•×‘×¥
        wav_path = to_wav_16k_mono(file)

        # ×ª××œ×•×œ Whisper
        segments, info = asr.transcribe(
            wav_path, beam_size=5, language=language, vad_filter=True,
            vad_parameters=dict(min_silence_duration_ms=500)
        )

        transcription = [
            {"start": round(s.start, 2), "end": round(s.end, 2), "text": s.text.strip()}
            for s in segments
        ]

        # ×–×™×”×•×™ ×“×•×‘×¨×™× ×¢× WhisperX
        logger.info("ğŸ™ï¸ ××–×”×” ×“×•×‘×¨×™× ×¢× WhisperX...")
        audio = whisperx.load_audio(wav_path)
        diarization_result = dia(audio)
        diarized_segments = whisperx.assign_word_speakers(diarization_result, {"segments": transcription})

        results = [
            {
                "start": round(seg["start"], 2),
                "end": round(seg["end"], 2),
                "text": seg["text"],
                "speaker": seg.get("speaker", "SPEAKER_UNKNOWN")
            }
            for seg in diarized_segments["segments"]
        ]

        return {
            "status": "success",
            "filename": file.filename,
            "language": language,
            "processing_time": round(time.time() - start_time, 2),
            "results": results,
            "speakers_count": len(set(r["speaker"] for r in results))
        }

    except Exception as e:
        logger.error(f"×©×’×™××”: {str(e)}")
        raise HTTPException(500, f"×©×’×™××ª ×©×¨×ª: {str(e)}")
    finally:
        if wav_path and os.path.exists(wav_path):
            os.remove(wav_path)
